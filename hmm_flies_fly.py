# -*- coding: utf-8 -*-
"""HMM_flies_fly

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zAVJfvIj7WSckLs4YIZloKRarAzBMaz7

*   Aarifah Ullah
*   Prof. Kasia Hitczenko
*   CSCI 4907.82 Natural Language Understanding
*   26 February 2024
"""

import nltk
from nltk.corpus import brown
from nltk.probability import FreqDist
import numpy as np

nltk.download('brown')
nltk.download('universal_tagset')

# Calculate starting probabilities
# This is provided in the homework; no need to change this

brown_sents = brown.tagged_sents(tagset='universal')
starting_pos = [sent[0][1] for sent in brown_sents]
freq_pos = FreqDist(starting_pos)
for item in freq_pos:
  freq_pos[item] = freq_pos[item] / len(starting_pos)

#Calculate emission probabilities, case insensitive
#Remember to ignore case and treat "Flies" the same as "flies"
#emission probability = P('fly'|VERB), meaning how likely the POS class VERB will pick 'fly' as one of is examples out of all possible words that are also labelled as VERBS

from collections import defaultdict, Counter

brown_words = brown.tagged_words(tagset='universal')
word_tags_counts = defaultdict(Counter) #track words with their POS & how many times it shows up with that POS
for word, pos in brown_words:
  word_tags_counts[word][pos] += 1

#the associated part of speech tags for "flies" and "fly" (case-insensitive)
print("POS Tag sets:")
print('flies', word_tags_counts['flies'])
print('Flies', word_tags_counts['Flies'])
print('fly', word_tags_counts['fly'])
print('Fly', word_tags_counts['Fly'])

verb_count = 0
noun_count = 0
#iterate through list of words
for word in word_tags_counts:
  if "VERB" in word_tags_counts[word]: #count how many words are classified as a VERB
    verb_count += 1
  if "NOUN" in word_tags_counts[word]: #count how many words are classified as a NOUN
    noun_count += 1

#flies/Flies emission probability:
flies_noun_count = word_tags_counts['flies'].get("NOUN") + word_tags_counts['Flies'].get("NOUN") #returns 8
flies_verb_count = word_tags_counts['flies'].get("VERB")
flies_given_noun_probability = flies_noun_count / noun_count #emission proabability P('flies/Flies'|NOUN)
flies_given_verb_probability = flies_verb_count / verb_count # P('flies/Flies'|VERB)
print("'flies' emission probabilities:")
print("P('flies'|NOUN) = ", flies_given_noun_probability)
print("P('flies'|VERB) = ", flies_given_verb_probability)

#fly/Fly emission probability:
fly_noun_count = word_tags_counts['fly'].get("NOUN") + word_tags_counts['Fly'].get("NOUN") #returns 15
fly_verb_count = word_tags_counts['fly'].get("VERB")
fly_given_noun_probability = fly_noun_count / noun_count #emission proabability P('fly/Fly'|NOUN)
fly_given_verb_probability = fly_verb_count / verb_count # P('fly/Fly'|VERB)
print("'fly' emission probabilities:")
print("P('fly'|NOUN) = ", fly_given_noun_probability)
print("P('fly'|VERB) = ", fly_given_verb_probability)

#Calculate transition probabilities
word_tag_pairs = list(nltk.bigrams(brown_words))

verb_given_verb_count = 0 #[0,0]
noun_given_verb_count = 0 #[0,1]
verb_given_noun_count = 0 #[1,0]
noun_given_noun_count = 0 #[1,1]

all_given_verb_count = 0 #count all POS instance pairs for verbs
all_given_noun_count = 0 #count all POS instance pairs for nouns

for ((word1,pos1),(word2,pos2)) in word_tag_pairs: #iterate through all pairs of consecutive words / POS tags
  if((pos1 == "VERB") & (pos2 == "VERB")):
    verb_given_verb_count += 1 #returns 33672
  if((pos1 == "VERB") & (pos2 == "NOUN")):
    noun_given_verb_count += 1 #returns 17851
  if((pos1 == "VERB")):
    all_given_verb_count += 1 #returns 182750
  if((pos1 == "NOUN") & (pos2 == "VERB")):
    verb_given_noun_count += 1 #returns 43819
  if((pos1 == "NOUN") & (pos2 == "NOUN")):
    noun_given_noun_count += 1 #returns 41309
  if((pos1 == "NOUN")):
    all_given_noun_count += 1 #returns 275558

#final transmission probabilities are the ratios between a specific count over general count
verb_given_verb = verb_given_verb_count / all_given_verb_count
noun_given_verb = noun_given_verb_count / all_given_verb_count
verb_given_noun = verb_given_noun_count / all_given_noun_count
noun_given_noun = noun_given_noun_count / all_given_noun_count

print("transmission probabilities:")
print("P(VERB|VERB) = ",verb_given_verb)
print("P(NOUN|VERB) = ",noun_given_verb)
print("P(VERB|NOUN) = ",verb_given_noun)
print("P(NOUN|NOUN) = ",noun_given_noun)
#please refer to the other homework document for the drawn matrix, the Virterbi algorithm, and change in one of the probabilities

#Changing the calculation of one of the probabilities

#Instead of the distribution calculated for the starting probabilites, we are now going to assume that each "Universal" POS tag is equally likely
#For 12 classes, the chance of one being selected is 1/12 =~ .08333

"""## Part 1 Hidden Markov Models
### Answers to Questions
##### 1. In the Brown subcorpus with Universal tags, what is the set of part-of-speech tags we observe as labels for the words in our sentence: "flies" and "fly"?
Assuming that "fly" and "Fly", "flies" and "Flies" are the same words respectively, the set of POS is given by:

*   flies/Flies: {'NOUN', 'VERB'}
*   fly/Fly: {'VERB', 'NOUN'}

##### 2. Provide all non-zero emission proabilities for "flies" and "fly" based on the tagged Brown subcorpus. (Treat "Flies" and "flies" as the same)

*   'flies' emission probabilities: P('flies'|NOUN) = 0.00023525260248191495 P('flies'|VERB) =  0.000351000351000351
*   'fly' emission probabilities: P('fly'|NOUN) = 0.00044109862965359056 P('fly'|VERB) =  0.0015795015795015794

##### 3. Give an example of an emission probability for 'flies' or 'fly' that is zero.

*   P('fly'|ADVERB) = 0. This is because in the Brown corpus, fly never shows up as an adverb, so the chance that the class ADVERB generates the word fly as one of its examples is zero.

##### 4. Normally, you would want to calculate the transition probability matrix between all pairs of possible states (i.e., parts-of-speech). Given that there are 12 parts-of-speech in the universal tagset, this would involve creating a 12x12 matrix. However, for this problem, it is sufficient to create a 2x2 matrix. Provide that transition probability matrix and its values, and explain why no other transition probabilities are needed in order to correctly tag the sentence “Flies fly”.
*   No other transmission probability is needed for this example sentence because "flies" and "fly" only showed up in the Brown corpus as a verb or noun. We do not need to know how likely it is to go from a verb to an adjective, if "Flies" turned out to be a verb and "fly" could only be a noun or verb.
*   Please see other document for the drawn matrix.

##### 5. Walk through the Viterbi algorithm to show how the sentence “Flies fly” would be tagged. Your answer can take the form of a 2x2 matrix where the rows correspond to the parts of speech that “flies” and “fly” can take (hint: refer to #1 and #2) and the columns correspond to each word in the to-be-tagged sentence.
*   Using the Viterbi algorithm, the sentence "Flies fly" would be tagged as "Flies" is a noun followed by "fly" as a verb.

##### 6. Make a change to the emission probabilities, transition probabilities, or starting probabilities (or any combination thereof) in such a way that it changes how the sentence would be tagged (but make sure all probabilities that should sum to 1 still do). Provide your change and what the resulting part of speech tags would be. Explain the intuition for why your change to the probabilities causes a change in tagging.
*   I changed the starting probabilities for any POS tag to be all equally likely. This changed the original tagged sentence to rather be "Flies fly" as both verbs. I think causing them all to be likely chances put less weight on more probable combinations given the Brown corpus text and put more weight to other probabilites. The tagging now just relied on emission and transmission probabilites.

###Consulted Resources
*   Outlined how to work with the brown.tagged_words(): https://stackoverflow.com/questions/26251945/nltk-brown-corpus-tags

"""